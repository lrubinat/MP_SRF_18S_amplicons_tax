---
title: "MP_SRF_18S_amplicons_tax"
author: "lrubinat"
date: "05/03/2016"
output:
  html_document:
    theme: united
    toc: yes
  pdf_document:
    highlight: zenburn
    toc: yes
---

<!--- INITIALIZATION
```{r, echo=FALSE}
#error hook to kill knitr in case of errors
library(knitr)
knit_hooks$set(error = function(x, options) stop(x))
opts_chunk$set(cache=TRUE, autodep=TRUE)
```
--->

# 1) 18S amplicons

Data uploading:

``` {r load_data, echo=FALSE, message=FALSE}
setwd("/home/laura/Documents/TFM/genwork/data_analysis/MP_18S_SRF_amplicons/MP_SRF_18S_amplicons_tax/")

#read data 
tb18_tax <- read.table(file="/home/laura/Documents/TFM/home/data/MALASPINA/Malaspina_18S_Surface/table_with_BLAST/MP_18S_SRF_MAS_BM_SILVA_classif_tab_filtered.txt", head=TRUE, fill=TRUE)

#table dimensions and format before setting column names
dim(tb18_tax) # 54979   132
tb18_tax[1:5,1:5]

#row names = OTU name (option A)
row.names(tb18_tax)<-tb18_tax[,1]

#row names = row number (option B)
#rownames(otu_tb18) <- 1:nrow(otu_tb18)

tb18_tax<-tb18_tax[,-1]
tb18_tax[is.na(tb18_tax)]<-0

dim(tb18_tax)
tb18_tax[1:5,1:5]

#table with taxonomi classification alone
tb18_class <- tb18_tax[,125:131]
dim(tb18_class)
tb18_class[1:5,1:7]

#table with occurence data alone
tb18_tax_occur <- tb18_tax[, 1:124]
dim(tb18_tax_occur) # 54979   124
tb18_tax_occur[1:5,1:5]

amplicons_per_sample_tb18<-colSums(tb18_tax_occur)
amplicons_per_sample_tb18[which(colSums(tb18_tax_occur)<8522)]
# sample st054 has less than 8522 reads.

#remove samples with less than 8522 reads
tb18_tax_occur_min8522 <- tb18_tax_occur[,colSums(tb18_tax_occur) >= 8522]
dim(tb18_tax_occur_min8522)


#remove samples with less than 5000 reads in the MP_18S_ss5000 dataset (so that we can compare the relative abundance of 16S and 18S OTUs considering the same samples)
#otu_tb16_min5000_v2<-subset(otu_tb16_min5000, select=-c(MD985))
```

Table dimensions and content outline:

```{r starting_dataset, echo=FALSE}
dim(tb18_tax_occur_min8522)
tb18_tax_occur_min8522[1:5,1:5]
```

Minimum number of reads per station:

```{r reads_per_sample_overview1, echo=1}
min(colSums(tb18_tax_occur_min8522)) 
#8522
```

Maximum number of reads per station:

```{r reads_per_sample_overview2, echo=1}
max(colSums(tb18_tax_occur_min8522)) 
# max: 936570
```

Identification of station with higher number of reads:

```{r reads_per_sample_overview3, echo=TRUE}
amplicons_per_sample<-colSums(tb18_tax_occur_min8522)
amplicons_per_sample[which(colSums(tb18_tax_occur_min8522)>900000)]
```

Overall reads per sample:

``` {r reads_per_sample_overview4, echo=FALSE}
plot(sort(colSums(tb18_tax_occur_min8522)), pch=19, xlab="sample", ylab="reads per sample", cex=0.9)
```


## 2) Normalization

Let's normalize the original dataset by randomly subsampling 8522 reads in each station:

``` {r species_richness_rarefaction1, echo=TRUE}
library(vegan)
tb18_tax_occur_min8522_t<-t(tb18_tax_occur_min8522)
tb18_tax_occur_ss8522<-rrarefy(tb18_tax_occur_min8522_t, 8522)
```

The normalized table shows the following dimensions and format:

```{r species_richness_rarefaction2, echo=FALSE}
dim(tb18_tax_occur_ss8522)
tb18_tax_occur_ss8522[1:5,1:5]
```

Its content fits with the expected normalization values (8522 reads per station):

``` {r species_richness_rarefaction3, echo=TRUE}
rowSums(tb18_tax_occur_ss8522)
```

Let's check out how many OTUs don't appear in the new table:

```{r species_richness_rarefaction4, echo=1:5}
length(which(colSums(tb18_tax_occur_ss8522)==0)) 
```

There are 20077 OTUs that don't show any occurrence in the normalized data. Let's remove them from the table and take a look at its final dimensions:

```{r species_richness_rarefaction5, echo=1:3}
tb18_tax_occur_ss8522_no_cero<-tb18_tax_occur_ss8522[,-(which(colSums(tb18_tax_occur_ss8522)==0))]
dim(tb18_tax_occur_ss8522_no_cero)

#the final dimensions of the normalized table are 123 27067.
#20077 + 27067 = 47144
```

Datasets summary:
dim(tb18_tax) --> 47144   131
dim(tb18_tax_occur) --> 47144   124
dim(tb18_tax_occur_ss8522_no_cero) --> 123 27067

Let's add the taxonomic classification to the left OTUs by merging "tb18_tax_occur_ss8522_no_cero" with "tb18_tax".

```{r merge_tables, echo=FALSE}
tb18_tax_occur_ss8522_no_cero_t<-t(tb18_tax_occur_ss8522_no_cero)
tb18_ss8522_tax<-merge(tb18_tax_occur_ss8522_no_cero_t,tb18_class, by="row.names")

dim(tb18_ss8522_tax)
tb18_ss8522_tax[1:5,1:5]

#fix OTU_no as new row
rownames(tb18_ss8522_tax)=tb18_ss8522_tax$Row.names

#add OTU_no as rowname
rownames.tb18_ss8522_tax<-tb18_ss8522_tax[,1]
tb18_ss8522_tax<-tb18_ss8522_tax[,-1]
#colnames(tb18_ss8522_tax, do.NULL=F)

dim(tb18_ss8522_tax)
tb18_ss8522_tax[1:5, 1:5]

#sort by OTU_no (split rowname, introduce no. into column "OTU_no" and sort)
tb18_ss8522_tax["OTU_no"] <- NA
tb18_ss8522_tax$OTU_no <- sapply(strsplit(rownames(tb18_ss8522_tax),split= "\\_"),'[',2)
tb18_ss8522_tax$OTU_no <- as.numeric(as.character(tb18_ss8522_tax$OTU_no))
tb18_ss8522_tax_sorted<-tb18_ss8522_tax[order(tb18_ss8522_tax$OTU_no, decreasing = FALSE), ]

dim(tb18_ss8522_tax_sorted)
tb18_ss8522_tax_sorted[1:5,1:5]
```

```{r select_phototrophs, echo=FALSE}
tb18_phototrophs <- tb18_ss8522_tax_sorted[which(tb18_ss8522_tax_sorted$MAS_plus_BM_plus_SILVA_class != "NA"),]
dim(tb18_phototrophs)
tb18_phototrophs[1:5,123]
```

```{r aggregate, echo=FALSE}

class_summary_reads_per_class<-aggregate(rowSums(tb18_phototrophs[1:123]), list(tb18_phototrophs$MAS_plus_BM_plus_SILVA_class), sum)
# count the different groups

class_summary_otus_per_class<-aggregate(rowSums(tb18_phototrophs[1:123]), list(tb18_phototrophs$MAS_plus_BM_plus_SILVA_class), length)

attach(class_summary_reads_per_class)
class_summary_reads_per_class_order<-class_summary_reads_per_class[order(-x),]
detach(class_summary_reads_per_class)
class_summary_reads_per_class_order

attach(class_summary_otus_per_class)
class_summary_otus_per_class_order<-class_summary_otus_per_class[order(-x),]
detach(class_summary_otus_per_class)
class_summary_otus_per_class_order


#class_summary_reads<-aggregate(sum~class, data=otutab_full_wTax, FUN="sum") 
# sum reads different groups
```


# 2) 16S amplicons

Data uploading:

``` {r load_data, echo=FALSE, message=FALSE}
#setwd("/genwork/lrubinat")
#setwd("/home/laura/Documents/TFM/genwork/data_analysis/MP_16S_SRF_amplicons/MP_SRF_16S_amplicons_tax/")

#read data 
tb16_tax <- read.table(file="/home/laura/Documents/TFM/home/data/MALASPINA/Malaspina_16S_Surface/table_with_BLAST/MP_16S_SRF_tax_classif_tab.txt", head=TRUE, fill=TRUE)

#table dimensions and format before setting column names
dim(tb16_tax) # 54979   132
tb16_tax[1:5,1:5]

#row names = OTU name (option A)
row.names(tb16_tax)<-tb16_tax[,1]

#row names = row number (option B)
#rownames(otu_tb16) <- 1:nrow(otu_tb16)

tb16_tax<-tb16_tax[,-1]
tb16_tax[is.na(tb16_tax)]<-0

dim(tb16_tax)
tb16_tax[1:5,1:5]

#table with taxonomi classification alone
tb16_class <- tb16_tax[,125:130]
dim(tb16_class)
tb16_class[1:5,1:6]

#table with occurence data alone
tb16_tax_occur <- tb16_tax[, 1:124]
dim(tb16_tax_occur) # 54979   124
tb16_tax_occur[1:5,1:5]

amplicons_per_sample_tb16<-colSums(tb16_tax_occur)
amplicons_per_sample_tb16[which(colSums(tb16_tax_occur)<5862)]
# samples st122, st124, st137 and st144 have less than 5862 reads.

#remove samples with less than 5862 reads
tb16_tax_occur_min5862 <- tb16_tax_occur[,colSums(tb16_tax_occur) >= 5862]
dim(tb16_tax_occur_min5862)


#remove samples with less than 5000 reads in the MP_16S_ss5000 dataset (so that we can compare the relative abundance of 16S and 16S OTUs considering the same samples)
#otu_tb16_min5000_v2<-subset(otu_tb16_min5000, select=-c(MD985))
```

Table dimensions and content outline:

```{r starting_dataset, echo=FALSE}
dim(tb16_tax_occur_min5862)
tb16_tax_occur_min5862[1:5,1:5]
```

Minimum number of reads per station:

```{r reads_per_sample_overview1, echo=1}
min(colSums(tb16_tax_occur_min5862)) 
#5862
```

Maximum number of reads per station:

```{r reads_per_sample_overview2, echo=1}
max(colSums(tb16_tax_occur_min5862)) 
# max: 156843
```

Identification of station with higher number of reads:

```{r reads_per_sample_overview3, echo=TRUE}
amplicons_per_sample<-colSums(tb16_tax_occur_min5862)
amplicons_per_sample[which(colSums(tb16_tax_occur_min5862)>155000)]
```

Overall reads per sample:

``` {r reads_per_sample_overview4, echo=FALSE}
plot(sort(colSums(tb16_tax_occur_min5862)), pch=19, xlab="sample", ylab="reads per sample", cex=0.9)
```


## 2) Normalization

Let's normalize the original dataset by randomly subsampling 5862 reads in each station:

``` {r species_richness_rarefaction1, echo=TRUE}
library(vegan)
tb16_tax_occur_min5862_t<-t(tb16_tax_occur_min5862)
tb16_tax_occur_ss5862<-rrarefy(tb16_tax_occur_min5862_t, 5862)
```

The normalized table shows the following dimensions and format:

```{r species_richness_rarefaction2, echo=FALSE}
dim(tb16_tax_occur_ss5862)
tb16_tax_occur_ss5862[1:5,1:5]
```

Its content fits with the expected normalization values (5862 reads per station):

``` {r species_richness_rarefaction3, echo=TRUE}
rowSums(tb16_tax_occur_ss5862)
```

Let's check out how many OTUs don't appear in the new table:

```{r species_richness_rarefaction4, echo=1:5}
length(which(colSums(tb16_tax_occur_ss5862)==0)) 
```

There are 161 OTUs that don't show any occurrence in the normalized data. Let's remove them from the table and take a look at its final dimensions:

```{r species_richness_rarefaction5, echo=1:3}
tb16_tax_occur_ss5862_no_cero<-tb16_tax_occur_ss5862[,-(which(colSums(tb16_tax_occur_ss5862)==0))]
dim(tb16_tax_occur_ss5862_no_cero)

#the final dimensions of the normalized table are 123 30341.
#24638 + 30341 = 54979
```

Datasets summary:
dim(tb16_tax) --> 1315  130
dim(tb16_tax_occur) --> 1315  124
dim(tb16_tax_occur_ss5862_no_cero) --> 120 1154

Let's add the taxonomic classification to the left OTUs by merging "tb16_tax_occur_ss5862_no_cero" with "tb16_tax".

```{r merge_tables, echo=FALSE}
tb16_tax_occur_ss5862_no_cero_t<-t(tb16_tax_occur_ss5862_no_cero)
tb16_ss5862_tax<-merge(tb16_tax_occur_ss5862_no_cero_t,tb16_class, by="row.names")

dim(tb16_ss5862_tax)
tb16_ss5862_tax[1:5,1:5]

#fix OTU_no as new row
rownames(tb16_ss5862_tax)=tb16_ss5862_tax$Row.names

#add OTU_no as rowname
rownames.tb16_ss5862_tax<-tb16_ss5862_tax[,1]
tb16_ss5862_tax<-tb16_ss5862_tax[,-1]
#colnames(tb16_ss5862_tax, do.NULL=F)

dim(tb16_ss5862_tax)
tb16_ss5862_tax[1:5, 1:5]

#sort by OTU_no (split rowname, introduce no. into column "OTU_no" and sort)
tb16_ss5862_tax["OTU_no"] <- NA
tb16_ss5862_tax$OTU_no <- sapply(strsplit(rownames(tb16_ss5862_tax),split= "\\_"),'[',2)
tb16_ss5862_tax$OTU_no <- as.numeric(as.character(tb16_ss5862_tax$OTU_no))
tb16_ss5862_tax_sorted<-tb16_ss5862_tax[order(tb16_ss5862_tax$OTU_no, decreasing = FALSE), ]

dim(tb16_ss5862_tax_sorted)
tb16_ss5862_tax_sorted[1:5,1:5]
```

```{r select_phototrophs, echo=FALSE}
#tb16_phototrophs <- tb16_ss5862_tax_sorted[which(tb16_ss5862_tax_sorted$MAS_plus_BM_plus_SILVA_class != "NA"),]
dim(tb16_phototrophs)
tb16_phototrophs[1:5,1:5]
```

```{r aggregate, echo=FALSE}

class_summary<-aggregate(tb16_phototrophs, list(tb16_phototrophs$MAS_plus_BM_plus_SILVA_class), length)
# count the different groups

class_summary
#class_summary_reads<-aggregate(sum~class, data=otutab_full_wTax, FUN="sum") 
# sum reads different groups
```